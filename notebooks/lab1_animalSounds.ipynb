{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisIZ/Labs_DeepLearning/blob/test/notebooks/lab1_animalSounds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILen8cUCyaEW"
      },
      "source": [
        "# Laboratorio 1 - Animal Sound"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLkY6dQ4n5YL"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19R1JY3Pn5YL"
      },
      "outputs": [],
      "source": [
        "# Para redes neuronales\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "# Para visualización de resultados\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Para procesamiento de audio\n",
        "import torchaudio\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "# Para métricas\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Para manipulación de datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Otros\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVgXN70mr8mC"
      },
      "outputs": [],
      "source": [
        "# Libreria para decodificar audio en PyTorch tensors\n",
        "!pip install torchcodec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBU0DEaAn5YN"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLpjQshFn5YN"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk9N-Ds2n5YP"
      },
      "source": [
        "## Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLNq1uKQn5YP"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nBYk2ZPyjAu"
      },
      "source": [
        "## Descripción general\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm89Z3H-n5YQ"
      },
      "source": [
        "1. ¿Cuál es el objetivo del laboratorio?\n",
        "\n",
        "Queremos desarrollar un modelo de clasificación multi-etiqueta que pueda identificar correctamente los animales presentes en las grabaciones de la selva amazónica.\n",
        "\n",
        "2. ¿Qué tipo de datos tenemos en nuestro dataset?\n",
        "\n",
        "Tenemos los archivos de audio en formato WAV en las carpetas `train/` y `test/`. Además, en la primera carpeta, tenemos un archivo CSV que tiene como primera columna el nombre del archivo o `filename` y el resto de columnas son los nombres de cada especie. En total son 43 columnas, la primera contendra strings mientras que el resto contendrá valores 0 o 1 que indican la ausencia o presencia de la especie en la grabación.\n",
        "\n",
        "3. ¿Qué herramientas planeamos utilizar?\n",
        "\n",
        "En principio, planeamos utilizar `PyTorch` para los modelos (para que utilicen redes neuronales), `Matplotlib` para crear los gráficos de nuestros resultados (ej. modelar el descenso de la gradiente o como va evolucionando los losses en la etapa de training y testing), `TorchAudio` o `Librosa` para analizar features del dataset (ej. Mel-spectogram, MFCC, etc.), `Sklearn` para obtener metricas (ej. f1 score, multilabel confusion matrix, ROC/PR curves etc.) y utilizar métodos de reducción de dimensionalidad (ej. PSA, TSNE, etc.), `Pandas` y `Numpy` para manipular la data y sacar alguna métricas estadísticas (ej. promedio, cuartiles, etc.).\n",
        "\n",
        "4. ¿Qué restricciones tenemos?\n",
        "\n",
        "Además del plazo de entrega que es de 1 semana, tenemos recursos computacionales limitados. Trabajaremos con Colab para aprovechar la GPU que nos brinda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvC60IZ4pqo1"
      },
      "source": [
        "## Google Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUNYiKUQqJv4"
      },
      "source": [
        "Verificamos el acceso a Google Drive porque estamos desarrollando el laboratorio en VS Code con la extensión de Google Colab y desde la página web de este último para poder acceder sin problemas a la data en Google Drive que está como acceso directo (*symlink*) a una carpeta compartida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNtDghCqp52v"
      },
      "outputs": [],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0DJ5W-MU5VU"
      },
      "outputs": [],
      "source": [
        "MYDRIVE = Path(\"/content/drive/MyDrive\")\n",
        "\n",
        "hits = list(MYDRIVE.rglob(\"Animal Sounds\"))\n",
        "if not hits:\n",
        "    raise FileNotFoundError(\"No encuentro la carpeta 'Animal Sounds' dentro de MyDrive. Revisa que el acceso directo exista.\")\n",
        "\n",
        "DATA_ROOT = hits[0]          # la ruta “atajo”\n",
        "REAL_ROOT = hits[0].resolve() # la ruta real (como symlink)\n",
        "\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)\n",
        "print(\"REAL_ROOT:\", REAL_ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cRwyJoJVN1r"
      },
      "outputs": [],
      "source": [
        "TRAIN_7Z  = REAL_ROOT / \"train.7z\"\n",
        "TEST_7Z   = REAL_ROOT / \"test.7z\"\n",
        "TRAIN_CSV = REAL_ROOT / \"train.csv\"\n",
        "\n",
        "for p in [TRAIN_7Z, TEST_7Z, TRAIN_CSV]:\n",
        "    print(p, \"=>\", p.exists())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZmk6Jj-FmcQ"
      },
      "source": [
        "Habiendo encontrado las rutas de nuestros archivos:\n",
        "\n",
        "- La carpeta comprimida con los datos de training (`train.7z`)\n",
        "- La carpeta comprimida con los datos de testing (`test.7z`)\n",
        "- El archivo csv con las multi-etiquetas de cada video, indicando que especie suena en el audio, 1, y cual no, 0 (`train.csv`)\n",
        "\n",
        "En la siguiente sección, procedemos a descomprimir las carpetas, utilizando la herramienta `7z`, y revisar su contenido para poder realizar el Análisis Exploratorio de Datos (o *EDA* por sus siglas en Inglés)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeTa9uXQp7Ni"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVOnOdk2Gysz"
      },
      "source": [
        "Como trabajar con los datos directamente en Drive sería muy lento, procederemos a guardar el contenido de los archivos descomprimidos en `/content` que es el disco local temporal de la máquina de Colab que ofrece mayor velocidad de I/O. Al ser temporal, si se reinicia el entorno, es necesario repetir la descompresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJaEeswpJR91"
      },
      "outputs": [],
      "source": [
        "# Verificamos que haya suficiente espacio en /content\n",
        "!df -h /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrdlCHAqXEHa"
      },
      "outputs": [],
      "source": [
        "# Definimos rutas y creamos carpetas para guardar los datos\n",
        "DRIVE_DATA = Path(\"/content/drive/.shortcut-targets-by-id/1F5_zs2zy0oECJu6NSwXtSAsIL9HQJ3yf/Animal Sounds\")\n",
        "TRAIN_7Z = DRIVE_DATA / \"train.7z\"\n",
        "TEST_7Z  = DRIVE_DATA / \"test.7z\"\n",
        "TRAIN_CSV = DRIVE_DATA / \"train.csv\"\n",
        "\n",
        "OUT_BASE = Path(\"/content/data\")\n",
        "TRAIN_OUT = OUT_BASE / \"train\"\n",
        "TEST_OUT  = OUT_BASE / \"test\"\n",
        "\n",
        "TRAIN_OUT.mkdir(parents=True, exist_ok=True)\n",
        "TEST_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(TRAIN_7Z.exists(), TEST_7Z.exists(), TRAIN_CSV.exists())\n",
        "print(\"Extracción a:\", OUT_BASE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkHJ0A4GXghw"
      },
      "outputs": [],
      "source": [
        "# Extraemos los datos\n",
        "!7z x \"/content/drive/.shortcut-targets-by-id/1F5_zs2zy0oECJu6NSwXtSAsIL9HQJ3yf/Animal Sounds/train.7z\" -o\"/content/data/train\" -y\n",
        "!7z x \"/content/drive/.shortcut-targets-by-id/1F5_zs2zy0oECJu6NSwXtSAsIL9HQJ3yf/Animal Sounds/test.7z\"  -o\"/content/data/test\"  -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21GWOSgBpif9"
      },
      "outputs": [],
      "source": [
        "# Verificamos si estan los audios\n",
        "!find /content/data/train -maxdepth 2 -type f | head\n",
        "!find /content/data/test  -maxdepth 2 -type f | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzZXnufqpAua"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"/content/data\")\n",
        "\n",
        "def resolve_nested(split_dir: Path):\n",
        "    nested = split_dir / split_dir.name\n",
        "    return nested if nested.exists() else split_dir\n",
        "\n",
        "TRAIN_DIR = resolve_nested(DATA_DIR / \"train\")\n",
        "TEST_DIR  = resolve_nested(DATA_DIR / \"test\")\n",
        "\n",
        "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"TEST_DIR :\", TEST_DIR)\n",
        "print(\"Ejemplo train existe:\", TRAIN_DIR.exists())\n",
        "print(\"Ejemplo test existe :\", TEST_DIR.exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNDhJ5Grn5YQ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(TRAIN_CSV)\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zklb9z0spNWC"
      },
      "outputs": [],
      "source": [
        "f0 = df[\"filename\"].iloc[0]\n",
        "print(\"Archivo:\", f0)\n",
        "print(\"Existe?:\", (TRAIN_DIR / f0).exists())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ewjDScbqyi6"
      },
      "outputs": [],
      "source": [
        "drive_root = Path(\"/content/drive\")\n",
        "\n",
        "train7z = list(drive_root.rglob(\"train.7z\"))\n",
        "test7z  = list(drive_root.rglob(\"test.7z\"))\n",
        "csvs    = list(drive_root.rglob(\"train.csv\"))\n",
        "\n",
        "print(\"train.7z encontrados:\", len(train7z))\n",
        "print(\"test.7z encontrados:\", len(test7z))\n",
        "print(\"train.csv encontrados:\", len(csvs))\n",
        "\n",
        "# candidato: carpeta que tenga los 3 archivos\n",
        "candidates = []\n",
        "for p in train7z:\n",
        "    folder = p.parent\n",
        "    if (folder / \"test.7z\").exists() and (folder / \"train.csv\").exists():\n",
        "        candidates.append(folder)\n",
        "\n",
        "print(\"Carpetas candidatas:\", len(candidates))\n",
        "for c in candidates[:10]:\n",
        "    print(\" -\", c)\n",
        "\n",
        "DATASET_DIR = candidates[0]  # si sale >1, elegimos la que corresponde\n",
        "print(\"Usando DATASET_DIR:\", DATASET_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-emOIMcSck"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tif-WdxwstJA"
      },
      "source": [
        "### Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knjt0xgzcUTh"
      },
      "outputs": [],
      "source": [
        "label_cols = df.columns[1:]   # las columnas de todas las especies en un audio\n",
        "Y = df[label_cols].astype(int)\n",
        "\n",
        "k = Y.sum(axis=1)\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Num audios:\", len(df))\n",
        "print(\"Num clases:\", len(label_cols))\n",
        "print(\"Audios únicos:\", df[\"filename\"].nunique())\n",
        "print(\"Nulos totales:\", df.isna().sum().sum())\n",
        "print(\"Porcentaje audios sin etiquetas:\", (k==0).mean()*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa48bIb9swzY"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.hist(k, bins=np.arange(k.max()+2)-0.5)\n",
        "plt.xlabel(\"# etiquetas por audio\")\n",
        "plt.ylabel(\"conteo\")\n",
        "plt.title(\"Distribución de cardinalidad multi-label\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dF9qN4Qfcrgo"
      },
      "outputs": [],
      "source": [
        "# ¿cuántas etiquetas por audio?\n",
        "k = df[label_cols].sum(axis=1)\n",
        "k.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWArTSKacwXL"
      },
      "outputs": [],
      "source": [
        "# balance por clase\n",
        "class_counts = Y.sum().sort_values(ascending=False)\n",
        "print(\"Top 10 clases:\\n\", class_counts.head(10))\n",
        "print(\"\\nBottom 10 clases:\\n\", class_counts.tail(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxm4u2b_s6EQ"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(class_counts.values)\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"clase (ordenada por frecuencia)\")\n",
        "plt.ylabel(\"conteo (log)\")\n",
        "plt.title(\"Imbalance por clase (escala log)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EetB_F-2dWlg"
      },
      "outputs": [],
      "source": [
        "# porcentaje de precensia por clase\n",
        "class_pct = (class_counts / len(df) * 100).sort_values(ascending=False)\n",
        "class_pct.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnLIqonfs-Zv"
      },
      "outputs": [],
      "source": [
        "# clases con 0 o muy pocas apariciones\n",
        "zero_classes = class_counts[class_counts==0].index.tolist()\n",
        "rare_classes = class_counts[class_counts<100].index.tolist()\n",
        "print(\"Clases con 0 en train:\", zero_classes)\n",
        "print(\"Clases con <100 en train:\", len(rare_classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nFalA5FtAZU"
      },
      "source": [
        "### Co-ocurrencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0uGUriRtDTy"
      },
      "outputs": [],
      "source": [
        "# matriz co-ocurrencia (42x42)\n",
        "cooc = (Y.T @ Y).astype(int)\n",
        "np.fill_diagonal(cooc.values, 0)\n",
        "\n",
        "# top pares\n",
        "pairs = []\n",
        "for i, a in enumerate(label_cols):\n",
        "    for j, b in enumerate(label_cols):\n",
        "        if j <= i:\n",
        "            continue\n",
        "        c = cooc.loc[a, b]\n",
        "        if c > 0:\n",
        "            pairs.append((c, a, b))\n",
        "pairs.sort(reverse=True)\n",
        "\n",
        "print(\"Top 15 pares más comunes:\")\n",
        "for c,a,b in pairs[:15]:\n",
        "    print(f\"{a} + {b}: {c}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UACSjDcrtGnZ"
      },
      "source": [
        "### Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s61SRePdtIHH"
      },
      "outputs": [],
      "source": [
        "def audio_info_fast(path):\n",
        "    waveform, sample_rate = torchaudio.load(str(path))\n",
        "    num_channels = waveform.shape[0]\n",
        "    num_frames = waveform.shape[1]\n",
        "    duration = num_frames / sample_rate\n",
        "    return sample_rate, num_frames, duration, num_channels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIl3ReQetMKx"
      },
      "outputs": [],
      "source": [
        "sample_n = 1000\n",
        "sample_files = df[\"filename\"].sample(sample_n, random_state=SEED).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn2ITfbetOye"
      },
      "outputs": [],
      "source": [
        "srs, durs, chs = [], [], []\n",
        "for fn in tqdm(sample_files):\n",
        "    p = TRAIN_DIR / fn\n",
        "    sr, nframes, dur, nch = audio_info_fast(p)\n",
        "    srs.append(sr); durs.append(dur); chs.append(nch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RXD0OUTtQH5"
      },
      "outputs": [],
      "source": [
        "print(\"Sample rate (valores únicos aprox):\", sorted(set(srs))[:10], \"...\")\n",
        "print(\"Canales (valores únicos):\", sorted(set(chs)))\n",
        "print(\"Duración promedio:\", np.mean(durs), \"sec\")\n",
        "print(\"Duración min/max:\", np.min(durs), np.max(durs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpXfxAJVtRbU"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.hist(durs, bins=30)\n",
        "plt.xlabel(\"duración (s)\")\n",
        "plt.ylabel(\"conteo\")\n",
        "plt.title(\"Distribución de duración (muestra)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghu5at5OtTmM"
      },
      "outputs": [],
      "source": [
        "def plot_wave_and_melspec(wav_path, target_sr=22050):\n",
        "    y, sr = librosa.load(wav_path, sr=target_sr, mono=True)\n",
        "    plt.figure()\n",
        "    plt.plot(y)\n",
        "    plt.title(f\"Waveform | sr={sr} | len={len(y)/sr:.2f}s\")\n",
        "    plt.show()\n",
        "\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=1024, hop_length=512)\n",
        "    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "    plt.figure()\n",
        "    librosa.display.specshow(S_db, sr=sr, hop_length=512, x_axis='time', y_axis='mel')\n",
        "    plt.colorbar(format=\"%+2.0f dB\")\n",
        "    plt.title(\"Log-Mel Spectrogram\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moQC83V5tVJu"
      },
      "outputs": [],
      "source": [
        "# ejemplo: uno random\n",
        "fn = df[\"filename\"].iloc[0]\n",
        "plot_wave_and_melspec(str(TRAIN_DIR/fn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxpaOipJfyQR"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Model 1: MFCC(mean/std) + MLP"
      ],
      "metadata": {
        "id": "PSb5crP5hAoe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwfSPBztgGwZ"
      },
      "outputs": [],
      "source": [
        "# creamos carpeta para almacenar features\n",
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(CACHE_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClUeX4MPhGAe"
      },
      "outputs": [],
      "source": [
        "def extract_mfcc_stats(wav_path, target_sr=22050, n_mfcc=20):\n",
        "    # Cargamos sin forzar sr para respetar el original\n",
        "    y, sr = librosa.load(wav_path, sr=None, mono=True)\n",
        "\n",
        "    # Resample SOLO si fuera necesario (aunque según el EDA, siempre será 22050)\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    # stats (baseline)\n",
        "    feat = np.concatenate([mfcc.mean(axis=1), mfcc.std(axis=1)]).astype(np.float32)\n",
        "    return feat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RknqJ_Pohkat"
      },
      "outputs": [],
      "source": [
        "n_mfcc = 20\n",
        "feat_names = [f\"mfcc_mean_{i}\" for i in range(n_mfcc)] + [f\"mfcc_std_{i}\" for i in range(n_mfcc)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7kDRWAFra3w"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "H5_PATH = CACHE_DIR / \"train_mfcc_stats.h5\"\n",
        "KEY = \"train\"\n",
        "BATCH = 256  # ¿probar 256 o 512?\n",
        "\n",
        "# para evitar el error de \"string len limit\"\n",
        "MIN_ITEMSIZE = {\"filename\": 120}\n",
        "\n",
        "# =========================\n",
        "# (OPCIONAL) LIMPIAR H5 SI ESTÁ \"MAL CREADO\"\n",
        "# =========================\n",
        "# Si sale el error de itemsize, lo más limpio es borrar y regenerar\n",
        "if H5_PATH.exists():\n",
        "    print(\"H5 ya existe:\", H5_PATH)\n",
        "    print(\"Si este archivo fue creado antes SIN min_itemsize, podría fallar. \"\n",
        "          \"Si vuelve a fallar, bórralo (os.remove) y reintenta.\")\n",
        "    # Descomentar si se quiere forzar recreación\n",
        "    # os.remove(H5_PATH)\n",
        "\n",
        "# =========================\n",
        "# RECUPERAR PROCESADOS\n",
        "# =========================\n",
        "processed = set()\n",
        "if H5_PATH.exists():\n",
        "    try:\n",
        "        with pd.HDFStore(H5_PATH, mode=\"r\") as store:\n",
        "            if f\"/{KEY}\" in store.keys():\n",
        "                processed = set(store.select(KEY, columns=[\"filename\"])[\"filename\"].astype(str).tolist())\n",
        "    except Exception as e:\n",
        "        print(\"No se pudo leer el H5 para resume. Error:\", repr(e))\n",
        "        print(\"Recomendación: borrar el H5 y regenerar.\")\n",
        "        # os.remove(H5_PATH)\n",
        "        processed = set()\n",
        "\n",
        "print(\"Procesados previamente:\", len(processed))\n",
        "\n",
        "# =========================\n",
        "# EXTRACCIÓN + GUARDADO POR BATCH\n",
        "# =========================\n",
        "rows = []\n",
        "skipped_missing = 0\n",
        "skipped_errors = 0\n",
        "written = 0\n",
        "\n",
        "for i in tqdm(range(len(df)), desc=\"Extrayendo MFCC\"):\n",
        "    fn = str(df.loc[i, \"filename\"])\n",
        "\n",
        "    if fn in processed:\n",
        "        continue\n",
        "\n",
        "    wav_path = TRAIN_DIR / fn\n",
        "    if not wav_path.exists():\n",
        "        skipped_missing += 1\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        feat = extract_mfcc_stats(str(wav_path), target_sr=22050, n_mfcc=n_mfcc)\n",
        "    except Exception:\n",
        "        skipped_errors += 1\n",
        "        continue\n",
        "\n",
        "    row = {\"filename\": fn}\n",
        "    row.update({k: float(v) for k, v in zip(feat_names, feat)})\n",
        "\n",
        "    for c in label_cols:\n",
        "        row[c] = int(df.loc[i, c])\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "    # flush por batch\n",
        "    if len(rows) >= BATCH:\n",
        "        out = pd.DataFrame(rows)\n",
        "\n",
        "        # Guardar (con min_itemsize para filename)\n",
        "        out.to_hdf(\n",
        "            H5_PATH,\n",
        "            key=KEY,\n",
        "            mode=\"a\",\n",
        "            format=\"table\",\n",
        "            append=True,\n",
        "            data_columns=[\"filename\"],\n",
        "            min_itemsize=MIN_ITEMSIZE,\n",
        "            complib=\"blosc\",\n",
        "            complevel=5\n",
        "        )\n",
        "\n",
        "        written += len(out)\n",
        "        rows = []\n",
        "\n",
        "# flush final\n",
        "if rows:\n",
        "    out = pd.DataFrame(rows)\n",
        "    out.to_hdf(\n",
        "        H5_PATH,\n",
        "        key=KEY,\n",
        "        mode=\"a\",\n",
        "        format=\"table\",\n",
        "        append=True,\n",
        "        data_columns=[\"filename\"],\n",
        "        min_itemsize=MIN_ITEMSIZE,\n",
        "        complib=\"blosc\",\n",
        "        complevel=5\n",
        "    )\n",
        "    written += len(out)\n",
        "\n",
        "print(\"Listo. Guardado en:\", H5_PATH)\n",
        "print(\"Escritos nuevos:\", written)\n",
        "print(\"Saltados (faltan archivos):\", skipped_missing)\n",
        "print(\"Saltados (errores lectura/audio):\", skipped_errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lktXLlfy2tG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# OJO: Solo correrlo si necesitas volver a extraer y guardar los features\n",
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "H5_PATH = CACHE_DIR / \"train_mfcc_stats.h5\"\n",
        "\n",
        "if H5_PATH.exists():\n",
        "    os.remove(H5_PATH)\n",
        "    print(\"Borrado:\", H5_PATH)\n",
        "else:\n",
        "    print(\"No existe aún:\", H5_PATH)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbYnnFpxhsh6"
      },
      "outputs": [],
      "source": [
        "SAMPLE_N = 300\n",
        "sample_files = df[\"filename\"].sample(SAMPLE_N, random_state=42).tolist()\n",
        "wav_paths = [str(TRAIN_DIR / f) for f in sample_files]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QRayV5s7JEJ"
      },
      "outputs": [],
      "source": [
        "H5_PATH = \"/content/drive/MyDrive/Lab1_cache/train_mfcc_stats.h5\"\n",
        "df_feat = pd.read_hdf(H5_PATH, key=\"train\")\n",
        "\n",
        "print(\"Shape:\", df_feat.shape)\n",
        "print(\"Cols:\", df_feat.columns[:10].tolist())\n",
        "print(\"Filenames únicos:\", df_feat[\"filename\"].nunique())\n",
        "print(\"Nulos totales:\", df_feat.isna().sum().sum())\n",
        "\n",
        "df_feat.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Model 2: Log-Mel + CNN"
      ],
      "metadata": {
        "id": "KnMUr67khLta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creamos carpeta para almacenar features\n",
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(CACHE_DIR)"
      ],
      "metadata": {
        "id": "bfUDkkqhhmzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# MODEL 2: LOG-MEL + CNN\n",
        "# Feature Extraction (on-the-fly)\n",
        "# =========================\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Asegurar label_cols (orden oficial)\n",
        "if \"label_cols\" not in globals():\n",
        "    label_cols = df.columns[1:].tolist()\n",
        "\n",
        "N_CLASSES = len(label_cols)\n",
        "print(\"Num clases:\", N_CLASSES)\n",
        "\n",
        "# --- Config audio ---\n",
        "SR = 22050\n",
        "DUR_SEC = 3.0\n",
        "N_SAMPLES = int(SR * DUR_SEC)  # 66150 para 3 segundos\n",
        "N_MELS = 128\n",
        "\n",
        "# Log-Mel en torchaudio (rápido)\n",
        "mel_tf = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=SR,\n",
        "    n_fft=1024,\n",
        "    hop_length=256,\n",
        "    n_mels=N_MELS,\n",
        "    power=2.0\n",
        ")\n",
        "amp_to_db = torchaudio.transforms.AmplitudeToDB(stype=\"power\")\n",
        "\n",
        "def load_audio_fixed(path: Path, sr=SR, n_samples=N_SAMPLES):\n",
        "    \"\"\"\n",
        "    Carga wav y fuerza longitud fija (3s):\n",
        "    - si es más largo: recorta\n",
        "    - si es más corto: pad con ceros\n",
        "    Retorna tensor [1, n_samples]\n",
        "    \"\"\"\n",
        "    wav, file_sr = torchaudio.load(str(path))     # [C, T]\n",
        "    wav = wav.mean(dim=0, keepdim=True)           # mono [1, T]\n",
        "\n",
        "    if file_sr != sr:\n",
        "        wav = torchaudio.functional.resample(wav, file_sr, sr)\n",
        "\n",
        "    T = wav.shape[1]\n",
        "    if T >= n_samples:\n",
        "        wav = wav[:, :n_samples]\n",
        "    else:\n",
        "        wav = torch.nn.functional.pad(wav, (0, n_samples - T))\n",
        "\n",
        "    return wav  # [1, n_samples]\n",
        "\n",
        "def wav_to_logmel(wav: torch.Tensor):\n",
        "    \"\"\"\n",
        "    wav: [1, n_samples] -> log-mel: [1, n_mels, frames]\n",
        "    Normalizamos por archivo para estabilizar entrenamiento.\n",
        "    \"\"\"\n",
        "    S = mel_tf(wav)          # [1, n_mels, frames]\n",
        "    S = amp_to_db(S)         # log scale\n",
        "\n",
        "    # normalización por muestra (simple y efectiva para baseline)\n",
        "    S = (S - S.mean()) / (S.std() + 1e-6)\n",
        "    return S\n",
        "\n",
        "class LogMelDataset(Dataset):\n",
        "    def __init__(self, df_split, audio_dir: Path, label_cols, training=True):\n",
        "        self.df = df_split.reset_index(drop=True)\n",
        "        self.audio_dir = audio_dir\n",
        "        self.label_cols = label_cols\n",
        "        self.training = training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn = self.df.loc[idx, \"filename\"]\n",
        "        path = self.audio_dir / fn\n",
        "\n",
        "        wav = load_audio_fixed(path)\n",
        "        x = wav_to_logmel(wav)              # [1, 128, frames]\n",
        "\n",
        "        y = self.df.loc[idx, self.label_cols].values.astype(np.float32)\n",
        "        y = torch.from_numpy(y)             # [42]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "print(\"Listo: funciones + Dataset para log-mel.\")"
      ],
      "metadata": {
        "id": "uGPxjp-qkQLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "327UgBT0TwEB"
      },
      "source": [
        "## Models: Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCQP2_SXToa"
      },
      "source": [
        "### 1) MFCC(mean/std) + MLP\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0_SxxZXTzs1"
      },
      "outputs": [],
      "source": [
        "!ls -lah /content/drive/MyDrive\n",
        "!ls -lah /content/drive/MyDrive/Lab1_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAjn8N6hT8h2"
      },
      "outputs": [],
      "source": [
        "cands = list(Path(\"/content/drive\").rglob(\"train_mfcc_stats.h5\"))\n",
        "print(\"Encontrados:\", len(cands))\n",
        "for p in cands[:20]:\n",
        "    print(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBZJWyIDT-zi"
      },
      "outputs": [],
      "source": [
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "H5_PATH = CACHE_DIR / \"train_mfcc_stats.h5\"\n",
        "\n",
        "assert H5_PATH.exists(), f\"No encuentro: {H5_PATH}\"\n",
        "\n",
        "# mira qué keys tiene el HDF5 (para no fallar con el key)\n",
        "with pd.HDFStore(H5_PATH, mode=\"r\") as store:\n",
        "    print(\"Keys:\", store.keys())\n",
        "\n",
        "df_feat = pd.read_hdf(H5_PATH, key=\"train\")\n",
        "print(df_feat.shape)\n",
        "df_feat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEjjHhpzUA9B"
      },
      "outputs": [],
      "source": [
        "CACHE_DIR = Path(\"/content/drive/MyDrive/Lab1_cache\")\n",
        "H5_PATH   = CACHE_DIR / \"train_mfcc_stats.h5\"\n",
        "KEY       = \"train\"\n",
        "\n",
        "df_feat = pd.read_hdf(H5_PATH, key=KEY)\n",
        "print(\"Shape features:\", df_feat.shape)\n",
        "print(df_feat.head(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSeOtG97UGIT"
      },
      "outputs": [],
      "source": [
        "label_cols = df.columns[1:].tolist()  # orden oficial de Kaggle\n",
        "\n",
        "# features (X): solo MFCC stats\n",
        "feat_names = [c for c in df_feat.columns if c.startswith(\"mfcc_mean_\") or c.startswith(\"mfcc_std_\")]\n",
        "\n",
        "# sanity checks\n",
        "missing = [c for c in label_cols if c not in df_feat.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"Faltan estas columnas de labels en df_feat: {missing[:10]} ... (total {len(missing)})\")\n",
        "\n",
        "print(\"Num feats:\", len(feat_names))\n",
        "print(\"Num labels:\", len(label_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrT9IGvUUkhB"
      },
      "outputs": [],
      "source": [
        "X = df_feat[feat_names].values.astype(np.float32)\n",
        "y = df_feat[label_cols].values.astype(np.float32)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_dl = DataLoader(TensorDataset(torch.tensor(X_train), torch.tensor(y_train)),\n",
        "                      batch_size=512, shuffle=True)\n",
        "val_dl   = DataLoader(TensorDataset(torch.tensor(X_val), torch.tensor(y_val)),\n",
        "                      batch_size=1024, shuffle=False)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, out_dim),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP(X.shape[1], y.shape[1]).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ===== pos_weight =====\n",
        "pos = y_train.sum(axis=0)\n",
        "neg = y_train.shape[0] - pos\n",
        "pos_weight = neg / (pos + 1e-6)\n",
        "\n",
        "# Para clases con 0 positivos, pos_weight se vuelve enorme -> clamp\n",
        "pos_weight = np.clip(pos_weight, 1.0, 20.0)\n",
        "\n",
        "crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=device))\n",
        "\n",
        "def eval_model(th=0.5):\n",
        "    model.eval()\n",
        "    all_pred, all_true = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            prob = torch.sigmoid(model(xb)).cpu().numpy()\n",
        "            all_pred.append(prob)\n",
        "            all_true.append(yb.cpu().numpy())\n",
        "\n",
        "    P = np.vstack(all_pred)\n",
        "    T = np.vstack(all_true)\n",
        "    Yhat = (P >= th).astype(int)\n",
        "\n",
        "    micro = f1_score(T, Yhat, average=\"micro\", zero_division=0)\n",
        "    macro_all = f1_score(T, Yhat, average=\"macro\", zero_division=0)\n",
        "\n",
        "    # Macro más interpretable: excluye clases sin positivos en la validación\n",
        "    mask = (T.sum(axis=0) > 0)\n",
        "    macro_nonzero = f1_score(T[:, mask], Yhat[:, mask], average=\"macro\", zero_division=0) if mask.any() else 0.0\n",
        "\n",
        "    return micro, macro_all, macro_nonzero\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = crit(model(xb), yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    micro, macro_all, macro_nonzero = eval_model(th=0.5)\n",
        "    print(f\"Epoch {epoch} | loss={total_loss/len(train_dl.dataset):.4f} | \"\n",
        "          f\"F1 micro={micro:.4f} | F1 macro(all)={macro_all:.4f} | F1 macro(nonzero)={macro_nonzero:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "je395erkfIHd"
      },
      "outputs": [],
      "source": [
        "def get_probs(model, dl, device):\n",
        "    model.eval()\n",
        "    probs_list, true_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dl:\n",
        "            xb = xb.to(device)\n",
        "            prob = torch.sigmoid(model(xb)).cpu().numpy()\n",
        "            probs_list.append(prob)\n",
        "            true_list.append(yb.numpy())\n",
        "    return np.vstack(probs_list), np.vstack(true_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np2w6ZXrfJSM"
      },
      "outputs": [],
      "source": [
        "def tune_thresholds_macro_f1(P, T, grid=None):\n",
        "    \"\"\"\n",
        "    P: probs (N,C)\n",
        "    T: true  (N,C) binario\n",
        "    Retorna thresholds (C,) que maximizan Macro F1 por clase.\n",
        "    \"\"\"\n",
        "    if grid is None:\n",
        "        grid = np.linspace(0.05, 0.95, 19)\n",
        "\n",
        "    C = T.shape[1]\n",
        "    thr = np.full(C, 0.5, dtype=np.float32)\n",
        "\n",
        "    for c in range(C):\n",
        "        # Si en validación no hay positivos para esa clase, no tiene sentido tunear\n",
        "        # Ponemos umbral 1.0 para evitar predecirla (mejor que adivinar)\n",
        "        if T[:, c].sum() == 0:\n",
        "            thr[c] = 1.0\n",
        "            continue\n",
        "\n",
        "        best_f1, best_t = -1.0, 0.5\n",
        "        for t in grid:\n",
        "            pred = (P[:, c] >= t).astype(int)\n",
        "            f1 = f1_score(T[:, c], pred, zero_division=0)\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_t = f1, t\n",
        "        thr[c] = best_t\n",
        "\n",
        "    return thr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwzl_E30fM2J"
      },
      "outputs": [],
      "source": [
        "# 1) probs/true de validación\n",
        "P_val, T_val = get_probs(model, val_dl, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKa-Ye4WfPiZ"
      },
      "outputs": [],
      "source": [
        "# 2) tunear thresholds\n",
        "thresholds = tune_thresholds_macro_f1(P_val, T_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwRzuRDUfSUk"
      },
      "outputs": [],
      "source": [
        "# 3) evaluar macro con thresholds\n",
        "Yhat = (P_val >= thresholds[None, :]).astype(int)\n",
        "macro_all = f1_score(T_val, Yhat, average=\"macro\", zero_division=0)\n",
        "\n",
        "mask = (T_val.sum(axis=0) > 0)\n",
        "macro_nonzero = f1_score(T_val[:, mask], Yhat[:, mask], average=\"macro\", zero_division=0) if mask.any() else 0.0\n",
        "\n",
        "print(\"Macro F1 (all):\", macro_all)\n",
        "print(\"Macro F1 (nonzero):\", macro_nonzero)\n",
        "print(\"Ejemplo thresholds (primeras 10):\", thresholds[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Log-Mel + CNN"
      ],
      "metadata": {
        "id": "k5l6kmzghx7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/drive/MyDrive\n",
        "!ls -lah /content/drive/MyDrive/Lab1_cache"
      ],
      "metadata": {
        "id": "7eNNNybgh9hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# MODEL 2: LOG-MEL + CNN\n",
        "# Training\n",
        "# =========================\n",
        "\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Split train/val\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "train_ds = LogMelDataset(df_train, TRAIN_DIR, label_cols, training=True)\n",
        "val_ds   = LogMelDataset(df_val,   TRAIN_DIR, label_cols, training=False)\n",
        "\n",
        "# Si tu GPU está por acabarse o estás en CPU: baja batch_size a 16 o 8\n",
        "BATCH_TRAIN = 32\n",
        "BATCH_VAL   = 64\n",
        "\n",
        "# num_workers: en Colab a veces 2 es ok; si te da error, pon 0\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH_VAL,   shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "class SmallAudioCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN pequeña para log-mel [B, 1, 128, T]\n",
        "    - Aprende patrones tiempo-frecuencia mejor que MFCC(mean/std)+MLP\n",
        "    - GAP para no depender del T exacto\n",
        "    \"\"\"\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),  # 128->64\n",
        "\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),  # 64->32\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.head = nn.Linear(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.gap(x).squeeze(-1).squeeze(-1)  # [B,64]\n",
        "        return self.head(x)                      # logits [B,42]\n",
        "\n",
        "model = SmallAudioCNN(N_CLASSES).to(device)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# pos_weight para imbalance (igual idea que tu MLP)\n",
        "Y_train = df_train[label_cols].values.astype(np.float32)\n",
        "pos = Y_train.sum(axis=0)\n",
        "neg = Y_train.shape[0] - pos\n",
        "pos_weight = neg / (pos + 1e-6)\n",
        "pos_weight = np.clip(pos_weight, 1.0, 20.0)\n",
        "\n",
        "crit = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight, device=device))\n",
        "\n",
        "def eval_macro_nonzero(model, dl, thr=0.30):\n",
        "    model.eval()\n",
        "    P_list, T_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in dl:\n",
        "            xb = xb.to(device)\n",
        "            logits = model(xb)\n",
        "            prob = torch.sigmoid(logits).cpu().numpy()\n",
        "            P_list.append(prob)\n",
        "            T_list.append(yb.numpy())\n",
        "\n",
        "    P = np.vstack(P_list)\n",
        "    T = np.vstack(T_list)\n",
        "    Yhat = (P >= thr).astype(int)\n",
        "\n",
        "    mask = (T.sum(axis=0) > 0)\n",
        "    macro_nonzero = f1_score(T[:, mask], Yhat[:, mask], average=\"macro\", zero_division=0) if mask.any() else 0.0\n",
        "    return macro_nonzero\n",
        "\n",
        "# Entrenamiento rápido (baseline)\n",
        "EPOCHS = 10\n",
        "PATIENCE = 3\n",
        "THR_VAL = 0.30  # threshold global para evaluar rápido\n",
        "\n",
        "best = -1.0\n",
        "bad = 0\n",
        "best_state = None\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for xb, yb in train_dl:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        loss = crit(model(xb), yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "\n",
        "    val_f1 = eval_macro_nonzero(model, val_dl, thr=THR_VAL)\n",
        "    print(f\"Epoch {epoch:02d} | loss={total_loss/len(train_dl.dataset):.4f} | val macro_nonzero@{THR_VAL}={val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best + 1e-4:\n",
        "        best = val_f1\n",
        "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        bad = 0\n",
        "    else:\n",
        "        bad += 1\n",
        "        if bad >= PATIENCE:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "# Restaurar mejor modelo\n",
        "model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
        "print(\"Best val macro_nonzero:\", best)"
      ],
      "metadata": {
        "id": "wLHUDl7zkTMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JppsW6SYfdjY"
      },
      "source": [
        "## Models: Testing and CSV Kaggle results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtgfzOhYfhuJ"
      },
      "source": [
        "### 1) MFCC(mean/std) + MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV0mMtYI31CP"
      },
      "outputs": [],
      "source": [
        "# ===== asegurar variables críticas =====\n",
        "\n",
        "# 1) TEST_DIR\n",
        "if \"TEST_DIR\" not in globals():\n",
        "    try:\n",
        "        TEST_DIR = Path(TEST_OUT) / \"test\" if (Path(TEST_OUT) / \"test\").exists() else Path(TEST_OUT)\n",
        "    except Exception:\n",
        "        raise NameError(\"TEST_DIR no está definido. Ejecuta primero las celdas de extracción/rutas.\")\n",
        "\n",
        "print(\"TEST_DIR =\", TEST_DIR)\n",
        "\n",
        "# 2) label_cols (orden oficial para Kaggle)\n",
        "if \"label_cols\" not in globals():\n",
        "    if \"df\" in globals():\n",
        "        label_cols = df.columns[1:].tolist()\n",
        "    else:\n",
        "        raise NameError(\"label_cols no está definido porque df no existe. Ejecuta primero la carga de train.csv.\")\n",
        "\n",
        "print(\"Num labels:\", len(label_cols))\n",
        "\n",
        "# 3) thresholds\n",
        "if \"thresholds\" not in globals():\n",
        "    raise NameError(\"thresholds no está definido. Ejecuta primero la celda de tuning de thresholds (validación).\")\n",
        "\n",
        "print(\"thresholds shape:\", thresholds.shape)\n",
        "\n",
        "# 4) model, feat_names\n",
        "for v in [\"model\", \"feat_names\", \"extract_mfcc_stats\", \"n_mfcc\", \"device\"]:\n",
        "    if v not in globals():\n",
        "        raise NameError(f\"Falta '{v}'. Ejecuta primero Feature Extraction y Model training.\")\n",
        "print(\"OK: variables listas para submission.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfFaAVq836Xt"
      },
      "outputs": [],
      "source": [
        "test_files = sorted([p.name for p in TEST_DIR.rglob(\"*.wav\")])\n",
        "print(test_files[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3akGvyK3-9b"
      },
      "outputs": [],
      "source": [
        "print(\"TEST_DIR existe?\", \"TEST_DIR\" in globals())\n",
        "print(\"df existe?\", \"df\" in globals())\n",
        "print(\"label_cols:\", len(label_cols) if \"label_cols\" in globals() else None)\n",
        "print(\"feat_names:\", len(feat_names) if \"feat_names\" in globals() else None)\n",
        "print(\"thresholds:\", thresholds.shape if \"thresholds\" in globals() else None)\n",
        "print(\"model existe?\", \"model\" in globals())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PS-eSCLWfVqm"
      },
      "outputs": [],
      "source": [
        "# --- Lo que necesitamos que exista en el notebook ---\n",
        "# TEST_DIR, extract_mfcc_stats, n_mfcc, feat_names, model, device, thresholds, label_cols\n",
        "\n",
        "# 0) Sanity checks\n",
        "assert len(label_cols) == 42, f\"label_cols debería tener 42 clases y tiene {len(label_cols)}\"\n",
        "assert thresholds.shape[0] == 42, f\"thresholds debería ser (42,) y es {thresholds.shape}\"\n",
        "\n",
        "# 1) Listar archivos test\n",
        "test_files = sorted([p.name for p in TEST_DIR.rglob(\"*.wav\")])\n",
        "print(\"Test audios:\", len(test_files), \"| ejemplo:\", test_files[:3])\n",
        "\n",
        "# 2) Extraer MFCC stats para test\n",
        "rows = []\n",
        "for fn in tqdm(test_files, desc=\"Extrayendo MFCC (test)\"):\n",
        "    wav_path = TEST_DIR / fn\n",
        "    feat = extract_mfcc_stats(str(wav_path), target_sr=22050, n_mfcc=n_mfcc)\n",
        "\n",
        "    row = {\"filename\": fn}\n",
        "    row.update({k: float(v) for k, v in zip(feat_names, feat)})\n",
        "    rows.append(row)\n",
        "\n",
        "df_test_feat = pd.DataFrame(rows)\n",
        "print(\"df_test_feat:\", df_test_feat.shape)\n",
        "\n",
        "# 3) Inferencia en test\n",
        "X_test = df_test_feat[feat_names].values.astype(np.float32)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    probs_test = torch.sigmoid(model(torch.tensor(X_test, device=device))).cpu().numpy()\n",
        "\n",
        "assert probs_test.shape[1] == 42, f\"Tu modelo debería devolver 42 outputs y devuelve {probs_test.shape[1]}\"\n",
        "\n",
        "# 4) probs -> \"1 5 7\" (SIEMPRE espacio, NUNCA coma)\n",
        "def probs_to_pred_str(prob_row, thr):\n",
        "    active = np.where(prob_row >= thr)[0] + 1  # +1 para 1..42\n",
        "    active = active[(active >= 1) & (active <= 42)]\n",
        "    if active.size == 0:\n",
        "        return \"0\"\n",
        "    return \" \".join(map(str, active.tolist()))\n",
        "\n",
        "pred_str = [probs_to_pred_str(probs_test[i], thresholds) for i in range(len(probs_test))]\n",
        "\n",
        "# 5) Id = nombre del archivo SIN .wav (sin cortar nada)\n",
        "ids = [Path(fn).stem for fn in df_test_feat[\"filename\"].tolist()]\n",
        "\n",
        "sub = pd.DataFrame({\"Id\": ids, \"Predicted\": pred_str})\n",
        "\n",
        "# 6) Validaciones IMPORTANTES antes de guardar\n",
        "print(\"Columnas:\", sub.columns.tolist())\n",
        "assert sub.shape[1] == 2, \"El submission debe tener EXACTAMENTE 2 columnas: Id y Predicted\"\n",
        "assert sub[\"Id\"].str.contains(r\"\\.wav$\", regex=True).sum() == 0, \"Id no debe incluir .wav\"\n",
        "\n",
        "# Predicted: sin comas y dentro de 1..42\n",
        "bad_commas = sub[\"Predicted\"].str.contains(\",\", regex=False).sum()\n",
        "print(\"Filas con coma en Predicted:\", bad_commas)\n",
        "assert bad_commas == 0, \"Predicted NO debe contener comas. Debe separar con espacios.\"\n",
        "\n",
        "def max_index(s):\n",
        "    if s == \"0\":\n",
        "        return 0\n",
        "    return max(map(int, s.split()))\n",
        "\n",
        "mx = sub[\"Predicted\"].map(max_index).max()\n",
        "print(\"Máximo índice en Predicted:\", mx)\n",
        "assert mx <= 42, f\"Hay índices > 42 en Predicted (máximo={mx}). Eso está mal.\"\n",
        "\n",
        "print(sub.head(5))\n",
        "\n",
        "# 7) Guardar con nombre claro del modelo 1\n",
        "MODEL_TAG = \"model1_mfcc_mlp\"\n",
        "sub_path = Path(f\"/content/drive/MyDrive/Lab1_cache/submission_{MODEL_TAG}.csv\")\n",
        "\n",
        "# QUOTE_ALL ayuda a que Excel no “parta” el campo Predicted\n",
        "sub.to_csv(sub_path, index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "print(\"Guardado:\", sub_path)\n",
        "\n",
        "# 8) (Opcional) ver primeras líneas RAW del csv para confirmar formato\n",
        "with open(sub_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for _ in range(5):\n",
        "        print(f.readline().strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJsGtPhy6ppL"
      },
      "outputs": [],
      "source": [
        "print(sub.head(5))\n",
        "print(\"Columnas:\", sub.columns.tolist())\n",
        "\n",
        "# verificamos que Predicted NO tenga comas y que max índice <= 42\n",
        "bad_commas = sub[\"Predicted\"].str.contains(\",\", regex=False).sum()\n",
        "print(\"Filas con coma:\", bad_commas)\n",
        "\n",
        "def max_idx(s):\n",
        "    if s == \"0\": return 0\n",
        "    return max(map(int, s.split()))\n",
        "\n",
        "mx = sub[\"Predicted\"].map(max_idx).max()\n",
        "print(\"Max índice:\", mx)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Log-Mel + CNN"
      ],
      "metadata": {
        "id": "OIred2WDiJRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# MODEL 2: LOG-MEL + CNN\n",
        "# Testing + Kaggle CSV\n",
        "# =========================\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Threshold global (haz 2 submissions rápidas probando 0.30 y 0.25)\n",
        "THR_TEST = 0.30\n",
        "\n",
        "test_files = sorted([p.name for p in TEST_DIR.rglob(\"*.wav\")])\n",
        "print(\"Test audios:\", len(test_files))\n",
        "\n",
        "model.eval()\n",
        "pred_str = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for fn in tqdm(test_files, desc=\"Inferencia test (CNN)\"):\n",
        "        wav = load_audio_fixed(TEST_DIR / fn)     # [1, 66150]\n",
        "        x = wav_to_logmel(wav).unsqueeze(0)       # [1, 1, 128, frames]\n",
        "        x = x.to(device)\n",
        "\n",
        "        prob = torch.sigmoid(model(x)).cpu().numpy().reshape(-1)  # (42,)\n",
        "\n",
        "        active = np.where(prob >= THR_TEST)[0] + 1  # 1..42\n",
        "\n",
        "        # Anti-\"0\": si nada supera THR, usamos top-1 para no perder macro recall\n",
        "        if active.size == 0:\n",
        "            s = str(int(np.argmax(prob) + 1))\n",
        "        else:\n",
        "            active_sorted = sorted(active.tolist(), key=lambda k: prob[k-1], reverse=True)\n",
        "            s = \" \".join(map(str, active_sorted))\n",
        "\n",
        "        pred_str.append(s)\n",
        "\n",
        "sub = pd.DataFrame({\n",
        "    \"Id\": [Path(fn).stem for fn in test_files],\n",
        "    \"Predicted\": pred_str\n",
        "})\n",
        "\n",
        "# Sanity checks\n",
        "print(\"Filas con Predicted=='0':\", (sub[\"Predicted\"] == \"0\").sum())\n",
        "bad_commas = sub[\"Predicted\"].str.contains(\",\", regex=False).sum()\n",
        "print(\"Filas con coma:\", bad_commas)\n",
        "\n",
        "MODEL_TAG = f\"model2_logmel_cnn_thr{THR_TEST}\"\n",
        "sub_path = Path(f\"/content/drive/MyDrive/Lab1_cache/submission_{MODEL_TAG}.csv\")\n",
        "sub.to_csv(sub_path, index=False, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "print(\"Guardado:\", sub_path)\n",
        "print(sub.head())"
      ],
      "metadata": {
        "id": "8M_SO-M9iN62"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}