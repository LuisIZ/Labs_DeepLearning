# Labs_DeepLearning

Este repositorio fue creado con el propósito de desarrollar los laboratorios de mi curso de Deep Learning en base a mis conocimientos y con ayuda de herramientas de IA como ChatGPT, Gemini, etc.

## Laboratorios

1. El [laboratorio 1](notebooks/lab1_animalSounds.ipynb) consistía en crear un modelo que identifique a animales a partir de sonidos grabados en la amazonia. El desafío era que, en el audio, existía la posibilidad de esuchar, al mismo tiempo, a más de 1 de las 42 especies que estaba tratando de identificar y clasificar. Esto con el propósito de ayudar a los investigadores monitorear estas especies, estudiar sus comportamientos y detectar cambios en el ecosistema a gran escala. El reconocimiento de sonidos en entornos naturales es una herramienta clave en la conservación de la biodiversidad y, el código que desarrollé trata de ayudar de ayudar a esa causa.
2. El [laboratorio 2](notebooks/lab2_FishEye.ipynb) consistía en crear un modelo que identifique una única clase, personas. El desafío era que teniamos que identificar a las personas en las imagenes pero estas tenían algo en particular que eran imagenes tomadas por cámaras cenitales con lente fisheye. Además, cada una incluía una iluminación desafiante (luz apagada, IR con/ sin filtro), oclusiones fuertes y actividad dinámica. Todo ello con el objetivo de desarrollar un detector moderno con cajas rotadas: lectura del dataset, data augmentation, diseño/elección de arquitectura (one-stage/ two-stage/ rotated heads), calibración de puntajes y evaluación rigurosa.
3. El [laboratorio 3](notebooks/lab3_planningQwen.ipynb) consistía en diseñar algoritmos y arquitecturas de prompts (como CoT, ToT o GoT) utilizando el modelo de lenguaje Qwen3-8B para resolver problemas lógicos de planificación de varios pasos dentro de una simulación virtual. El desafío era que el modelo debía interpretar escenarios descritos en lenguaje natural (relacionados a dominios de bloques u objetos) y traducirlos a un plan de acciones canónicas exactas, sin fallos de formato. Además, la inferencia debía configurarse de manera estrictamente determinista (temperatura de 0.0) y cumplir con un límite de tiempo de ejecución riguroso por tarea. Todo ello con el objetivo de explorar las capacidades de razonamiento estructurado (AI Planning) de los LLMs modernos y desarrollar código robusto para la extracción de predicciones automatizadas.